[DEFAULT]
max_tokens = 2048
temperature = 0.7
context_length = 4096
timeout = 30

[models]
default = http://localhost:8080/v1/chat/completions
ollama = http://localhost:11434/api/chat
lmstudio = http://localhost:1234/v1/chat/completions
openai_compatible = http://localhost:8000/v1/chat/completions

[tools]
enable_file_operations = true
enable_terminal_commands = true
enable_image_analysis = true
safe_mode = true
